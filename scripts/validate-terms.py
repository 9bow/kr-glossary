#!/usr/bin/env python3
"""
ìš©ì–´ì§‘ êµ¬ì¡° ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
GitHub PRì—ì„œ ìš©ì–´ êµ¬ì¡°ì˜ ìœ íš¨ì„±ì„ ê²€ì¦
"""

import json
import os
import sys
from pathlib import Path
import jsonschema

class TermValidator:
    def __init__(self):
        self.base_path = Path(__file__).parent.parent
        self.terms_dir = self.base_path / "data/terms"

        # ìš©ì–´ ìŠ¤í‚¤ë§ˆ ì •ì˜ (ë‹¤ì¤‘ ì •ì˜ ì§€ì›)
        self.term_schema = {
            "type": "object",
            "required": ["english", "korean", "status", "contributors", "metadata"],
            "properties": {
                "english": {"type": "string", "minLength": 1},
                "korean": {"type": "string", "minLength": 1},
                "alternatives": {"type": "array", "items": {"type": "string"}},
                "pronunciation": {"type": "string"},
                # ë‹¨ì¼ ì •ì˜ (í•˜ìœ„ í˜¸í™˜ì„±)
                "definition": {
                    "type": "object",
                    "required": ["korean", "english"],
                    "properties": {
                        "korean": {"type": "string"},
                        "english": {"type": "string"}
                    }
                },
                # ë‹¤ì¤‘ ì •ì˜ ì§€ì›
                "meanings": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "required": ["id", "title", "definition"],
                        "properties": {
                            "id": {"type": "string"},
                            "title": {
                                "type": "object",
                                "required": ["korean", "english"],
                                "properties": {
                                    "korean": {"type": "string"},
                                    "english": {"type": "string"}
                                }
                            },
                            "definition": {
                                "type": "object",
                                "required": ["korean", "english"],
                                "properties": {
                                    "korean": {"type": "string"},
                                    "english": {"type": "string"}
                                }
                            },
                            "context": {"type": "string"},
                            "domain": {"type": "string"},
                            "priority": {"type": "integer"},
                            "examples": {"type": "array"},
                            "references": {"type": "array"},
                            "contributors": {"type": "array"},
                            "validators": {"type": "array"},
                            "relatedPRs": {"type": "array"},
                            "metadata": {"type": "object"}
                        }
                    }
                },
                "examples": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "required": ["korean", "english"],
                        "properties": {
                            "korean": {"type": "string"},
                            "english": {"type": "string"},
                            "source": {"type": "string"},
                            "url": {"type": "string", "format": "uri"}
                        }
                    }
                },
                "references": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "required": ["title", "url", "type"],
                        "properties": {
                            "title": {"type": "string"},
                            "url": {"type": "string", "format": "uri"},
                            "type": {"type": "string"},
                            "year": {"type": "integer"}
                        }
                    }
                },
                "relatedTerms": {"type": "array", "items": {"type": "string"}},
                "status": {"enum": ["proposed", "validated", "deprecated"]},
                "contributors": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "required": ["githubUsername", "contributionType", "timestamp"],
                        "properties": {
                            "githubUsername": {"type": "string"},
                            "contributionType": {"enum": ["author", "reviewer", "translator"]},
                            "timestamp": {"type": "string", "format": "date-time"}
                        }
                    }
                },
                "validators": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "organizationId": {"type": "string"},
                            "validatedAt": {"type": "string", "format": "date-time"},
                            "validatorUsername": {"type": "string"}
                        }
                    }
                },
                "metadata": {
                    "type": "object",
                    "required": ["createdAt", "updatedAt", "version"],
                    "properties": {
                        "createdAt": {"type": "string", "format": "date-time"},
                        "updatedAt": {"type": "string", "format": "date-time"},
                        "version": {"type": "integer"},
                        "discussionUrl": {"type": "string", "format": "uri"}
                    }
                }
            }
        }

    def validate_all_terms(self):
        """ëª¨ë“  ìš©ì–´ íŒŒì¼ ê²€ì¦"""
        print("ğŸ” ìš©ì–´ êµ¬ì¡° ê²€ì¦ ì‹œì‘...")
        errors = []

        # ìš©ì–´ íŒŒì¼ë“¤ ê²€ì¦
        for filename in os.listdir(self.terms_dir):
            if filename.endswith('.json'):
                filepath = self.terms_dir / filename
                file_errors = self.validate_terms_file(filepath)
                errors.extend(file_errors)

        if errors:
            print(f"âŒ {len(errors)}ê°œì˜ ì˜¤ë¥˜ ë°œê²¬:")
            for error in errors:
                print(f"   â€¢ {error}")
            return False
        else:
            print("âœ… ëª¨ë“  ìš©ì–´ êµ¬ì¡° ê²€ì¦ í†µê³¼!")
            return True

    def validate_terms_file(self, filepath):
        """ìš©ì–´ íŒŒì¼ ê²€ì¦"""
        errors = []

        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # íŒŒì¼ì´ ë°°ì—´ì¸ì§€ í™•ì¸
            if isinstance(data, list):
                # ë°°ì—´ í˜•íƒœì˜ ìš©ì–´ íŒŒì¼
                for i, term in enumerate(data):
                    term_errors = self.validate_term(term, filepath.name, i)
                    errors.extend(term_errors)
            else:
                # ë‹¨ì¼ ìš©ì–´ ê°ì²´
                term_errors = self.validate_term(data, filepath.name, 0)
                errors.extend(term_errors)

        except json.JSONDecodeError as e:
            errors.append(f"{filepath.name}: JSON íŒŒì‹± ì˜¤ë¥˜ - {e}")
        except Exception as e:
            errors.append(f"{filepath.name}: íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ - {e}")

        return errors

    def validate_term(self, term, filename, index):
        """ê°œë³„ ìš©ì–´ ê²€ì¦"""
        errors = []

        try:
            # ìŠ¤í‚¤ë§ˆ ê²€ì¦
            jsonschema.validate(instance=term, schema=self.term_schema)

            # ì¶”ê°€ ê²€ì¦ ê·œì¹™ë“¤
            errors.extend(self.validate_term_rules(term, filename, index))

        except jsonschema.ValidationError as e:
            errors.append(f"{filename}[{index}]: ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨ - {e.message}")
        except Exception as e:
            errors.append(f"{filename}[{index}]: ê²€ì¦ ì˜¤ë¥˜ - {e}")

        return errors

    def validate_term_rules(self, term, filename, index):
        """ì¶”ê°€ ê²€ì¦ ê·œì¹™ë“¤"""
        errors = []

        # ìš©ì–´ê°€ definition ë˜ëŠ” meanings ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
        if not term.get('definition') and not term.get('meanings'):
            errors.append(f"{filename}[{index}]: definition ë˜ëŠ” meanings ì¤‘ í•˜ë‚˜ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤")

        # ì˜ì–´ ìš©ì–´ëŠ” ì²« ê¸€ìê°€ ëŒ€ë¬¸ìì—¬ì•¼ í•¨
        if not term['english'][0].isupper():
            errors.append(f"{filename}[{index}]: ì˜ì–´ ìš©ì–´ëŠ” ì²« ê¸€ìê°€ ëŒ€ë¬¸ìì—¬ì•¼ í•¨")

        # í•œêµ­ì–´ ìš©ì–´ëŠ” í•œê¸€ë¡œ ì‹œì‘í•´ì•¼ í•¨
        if not (ord('ê°€') <= ord(term['korean'][0]) <= ord('í£')):
            errors.append(f"{filename}[{index}]: í•œêµ­ì–´ ìš©ì–´ëŠ” í•œê¸€ë¡œ ì‹œì‘í•´ì•¼ í•¨")

        # ìµœì†Œ 1ê°œ ì´ìƒì˜ ì˜ˆì‹œê°€ ìˆì–´ì•¼ í•¨
        if len(term['examples']) < 1:
            errors.append(f"{filename}[{index}]: ìµœì†Œ 1ê°œ ì´ìƒì˜ ì˜ˆì‹œê°€ í•„ìš”í•¨")

        # ìµœì†Œ 1ê°œ ì´ìƒì˜ ì°¸ê³ ë¬¸í—Œì´ ìˆì–´ì•¼ í•¨
        if len(term['references']) < 1:
            errors.append(f"{filename}[{index}]: ìµœì†Œ 1ê°œ ì´ìƒì˜ ì°¸ê³ ë¬¸í—Œì´ í•„ìš”í•¨")

        # ì˜ì–´ ì •ì˜ì™€ í•œêµ­ì–´ ì •ì˜ê°€ ì„œë¡œ ë‹¬ë¼ì•¼ í•¨
        if term['definition']['english'] == term['definition']['korean']:
            errors.append(f"{filename}[{index}]: ì˜ì–´/í•œêµ­ì–´ ì •ì˜ê°€ ë™ì¼í•¨")

        # ìš©ì–´ ID í˜•ì‹ ê²€ì¦ (ì•ŒíŒŒë²³-ìˆ«ì í˜•ì‹)
        if not self.is_valid_term_id(term['id']):
            errors.append(f"{filename}[{index}]: ìš©ì–´ ID í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ (ì˜ˆ: neural-network-001)")

        return errors

    def is_valid_term_id(self, term_id):
        """ìš©ì–´ ID í˜•ì‹ ê²€ì¦"""
        parts = term_id.split('-')
        if len(parts) < 2:
            return False

        # ë§ˆì§€ë§‰ ë¶€ë¶„ì€ ìˆ«ìì—¬ì•¼ í•¨
        if not parts[-1].isdigit():
            return False

        # ì•ë¶€ë¶„ë“¤ì€ ì•ŒíŒŒë²³ê³¼ ìˆ«ìë§Œ í¬í•¨
        for part in parts[:-1]:
            if not part.replace('-', '').isalnum():
                return False

        return True

def main():
    validator = TermValidator()
    success = validator.validate_all_terms()

    if not success:
        print("\nğŸ’¡ ìˆ˜ì • ë°©ë²•:")
        print("   â€¢ ìš©ì–´ ID: neural-network-001 í˜•ì‹ìœ¼ë¡œ ì§€ì •")
        print("   â€¢ ì˜ì–´ ìš©ì–´: ì²« ê¸€ì ëŒ€ë¬¸ì")
        print("   â€¢ ìµœì†Œ 1ê°œì˜ ì˜ˆì‹œì™€ ì°¸ê³ ë¬¸í—Œ í¬í•¨")
        print("   â€¢ ì˜ì–´/í•œêµ­ì–´ ì •ì˜ê°€ ì„œë¡œ ë‹¤ë¦„")
        sys.exit(1)
    else:
        print("\nğŸ‰ ëª¨ë“  ìš©ì–´ ê²€ì¦ ì™„ë£Œ!")
        sys.exit(0)

if __name__ == "__main__":
    main()
